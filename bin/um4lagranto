#!/usr/bin/env python
# coding: utf-8
"""
Prepare MetUM LAM output for the Lagranto trajectory model
"""
import argparse
import cf_units
from collections import OrderedDict
import iris
import json
import netCDF4 as nc
import numpy as np
from path import Path
from shutil import rmtree
import subprocess as sb
import sys
from tqdm import tqdm
#
from arke.grid import unrotate_uv
from arke.coords import get_cube_datetimes

iris.FUTURE.netcdf_promote = True
iris.FUTURE.cell_datetime_objects = True


def parse_args(args=None):
    ap = argparse.ArgumentParser(__file__,
                                 description=__doc__,
                                 formatter_class=argparse.
                                 ArgumentDefaultsHelpFormatter,
                                 epilog=('Example of use:\n'
                                         'um4lagranto /path/to/config/file'))
    ap.add_argument('configs', type=str,
                    help='Path to config JSON file')
    return ap.parse_args(args)


def _make_dir(d, force=False):
    if d.exists():
        if force:
            rmtree(d)
            d.makedirs()
    else:
        d.makedirs()


def write_variable(ncds, data, varname,
                   datatype=None, dimensions=(), fill_value=None):
    if datatype is None:
        try:
            datatype = data.dtype
        except AttributeError:
            datatype = type(data)

    ncvar = ncds.createVariable(varname, datatype,
                                dimensions=dimensions, fill_value=fill_value)
    ncvar[:] = data


def create_const_file(cube, path, axes='zyx'):
    dt = get_cube_datetimes(cube)[0]
    file_name = '{dt:%Y%m%d}_cst'.format(dt=dt)
    ncdims = dict()
    for ax in axes:
        try:
            coord_len = len(cube.coord(axis=ax).points)
        except iris.exceptions.CoordinateNotFoundError:
            # TODO: test
            coord_len = 1
        dim_name = 'n' + ax
        if dim_name in ncdims:
            if coord_len != ncdims[dim_name]:
                dim_name += '_' + cube.attributes['l_name']
                ncdims[dim_name] = coord_len
        else:
            ncdims[dim_name] = coord_len
    _pollat = cube.coord_system().grid_north_pole_latitude
    _pollon = cube.coord_system().grid_north_pole_longitude
    plevs = cube.coord('pressure').points
    dummy_levs = np.zeros(plevs.shape)

    with nc.Dataset(path / file_name, mode='w') as ncds:
        for key, val in ncdims.items():
            ncds.createDimension(key, val)

        # rotated pole coordinates
        write_variable(ncds, _pollon, 'pollon')
        write_variable(ncds, _pollat, 'pollat')
        # Vertical levels
        write_variable(ncds, plevs[::-1], 'aklev', dimensions=('nz'))
        write_variable(ncds, dummy_levs, 'bklev', dimensions=('nz'))
        write_variable(ncds, dummy_levs, 'aklay', dimensions=('nz'))
        write_variable(ncds, dummy_levs, 'bklay', dimensions=('nz'))
        # min/max of longitude and latitude
        for i, ax in zip(('lon', 'lat'),
                         ('x',   'y')):
            _pnts = cube.coord(axis=ax).points
            for j in ('min', 'max'):
                _val = getattr(_pnts, j)()
                write_variable(ncds, _val, i + j)
            delta = np.diff(_pnts).mean()
            write_variable(ncds, delta, 'del' + i)
        # Date and time parameters
        write_variable(ncds, dt.year - 2000 + 100, 'starty')  # why?
        write_variable(ncds, dt.month, 'startm')
        write_variable(ncds, dt.day, 'startd')
        write_variable(ncds, dt.hour, 'starth')
        write_variable(ncds, dt.minute, 'starts')
        # Other parameters
        write_variable(ncds, 0, 'dattyp')
        write_variable(ncds, 0, 'datver')
        write_variable(ncds, 0, 'cstver')

    return file_name


def cubelist_to_netcdf(cubelist, ncds, reltime, master_cube='x_wind',
                       axes='zyx', constants_file_name='2013032412_cst'):
    # print('cubelist: ', cubelist)
    master = cubelist.extract(master_cube, strict=True)
    ncdims = OrderedDict()
    for ax in axes:
        for c in cubelist:
            try:
                coord_len = len(c.coord(axis=ax).points)
            except iris.exceptions.CoordinateNotFoundError:
                # TODO: test
                coord_len = 1
            dim_name = 'dim' + ax
            if dim_name in ncdims:
                # if coord_len != ncdims[dim_name]:
                relevant_dims = {k: v for k, v in ncdims.items()
                                 if k.startswith(dim_name)}
                if coord_len not in relevant_dims.values():
                    dim_name += '_' + c.attributes['l_name']
                    ncdims[dim_name] = coord_len
            else:
                ncdims[dim_name] = coord_len
    ncds.createDimension('time', 1)
    write_variable(ncds, reltime, 'time', dimensions=('time'))
    # print(ncds)

    # ncd_keys = []
    # ncd_vals = []
    # for key, val in ncdims.items():
    #     ncd_keys.append(key)
    #     ncd_vals.append(val)

    for key, val in ncdims.items():
        ncds.createDimension(key, val)

    for ax in axes:
        for i in ('min', 'max'):
            _name = 'dom{}{}'.format(ax, i)
            _value = getattr(master.coord(axis=ax).points, i)()
            setattr(ncds, _name, _value)
    if master.coord(axis='z').name() == 'pressure':
        ncds.domzmin, ncds.domzmax = ncds.domzmax, ncds.domzmin
    ncds.constants_file_name = constants_file_name
    return ncds


def cube_to_ncvar(cube, ncds, axes='zyx', stag=(0, 0, 0)):
    # really ugly solution...
    vardims = []
    for key, val in ncds.dimensions.items():
        ax = key[3]  # dimx, dimy, etc
        try:
            _coord_len = len(cube.coord(axis=ax).points)
        except:
            _coord_len = 1
        if _coord_len == val.size:
            vardims.append(key)
    vardims = tuple(sorted(vardims, reverse=True))
    ncvar = ncds.createVariable(cube.attributes['l_name'],
                                cube.dtype,
                                vardims)
    # print(cube.name())
    # print(cube.shape)
    # print(vardims)
    # print([*ncds.dimensions.items()])

    for n, ax in enumerate(axes):
        for i in ('min', 'max'):
            _name = '{}{}'.format(ax, i)
            try:
                _value = getattr(cube.coord(axis=ax).points, i)()
                setattr(ncvar, _name, _value)
                if cube.coord(axis='z').name() == 'pressure':
                    ncvar.zmin, ncvar.zmax = ncvar.zmax, ncvar.zmin
                    cube.data = cube.data[::-1, ...]  # TODO: more flexible
            except:
                pass
        setattr(ncvar, '{}stag'.format(ax), stag[n])

    ncvar.missing_value = 1e+30

    # ncvar.pollat = cube.coord_system().grid_north_pole_latitude
    # ncvar.pollon = cube.coord_system().grid_north_pole_longitude
    # print(cube.name(), cube.attributes['l_name'], cube.shape, vardims)

    ncvar[:] = cube.data

    return ncvar


def main(args=None):
    args = parse_args(args)

    with Path(args.configs).open('r') as fp:
        conf = json.load(fp)

    indir = Path(conf['paths']['input_dir'])
    infiles = indir / conf['file_wildcard']
    output_mode = conf['output_mode']
    if output_mode == 'local':
        outdir = Path(conf['paths']['output_dir'])
        _make_dir(outdir, conf['overwrite'])
    else:
        dest = ''
        for rd in conf.get('remote_dests', {}).values():
            if rd.get('switch', False):
                dest = f'{rd["user"]}@{rd["host"]}:{rd["path"]}'
        if not dest:
            # TODO: regex check?
            raise ValueError('Remote destination is not given or is incorrect')

    PNAMES = conf['names']['PNAMES']
    SNAMES = conf['names']['SNAMES']
    um_params = conf['um_params']

    pfile_mask = outdir / 'P{dt:%Y%m%d_%H}'
    sfile_mask = outdir / 'S{dt:%Y%m%d_%H}'

    cubelist = iris.load(infiles)

    cubes_out = iris.cube.CubeList()
    for ivar, vardict in um_params.items():
        if ivar in PNAMES + SNAMES:
            if 'um_name' in vardict:
                cube = cubelist.extract(vardict['um_name'], strict=True)
            elif 'stash' in vardict:
                attr_constr = iris.AttributeConstraint(STASH=vardict['stash'])
                cube = cubelist.extract(attr_constr, strict=True)
            else:
                raise KeyError('Unable to extract cube')
            cube.attributes['l_name'] = ivar
            if 'scl' in vardict:
                cube.data = cube.data * vardict['scl']
            if 'units' in vardict:
                cube.units = cf_units.Unit(vardict['units'])
            if 'regrid_to' in vardict:
                target = cubelist.extract(vardict['regrid_to'], strict=True)
                cube = cube.regrid(target, iris.analysis.Linear())
            cubes_out.append(cube)

    #
    # Write all data to netCDF files and send them to Grace
    #
    cst_file = create_const_file(cubes_out.extract('x_wind', strict=True),
                                 outdir)
    if output_mode != 'local':
        rsync_args = ['rsync', '-avqP', outdir / cst_file, dest]
        cmd = ', '.join(rsync_args)
        ierr = sb.check_call(rsync_args)

    dtrange = get_cube_datetimes(cubes_out.extract('x_wind', strict=True))
    for dt1 in tqdm(dtrange):
        t_delta = (dt1 - dtrange[-1]).total_seconds()/3600
        # print('Time: {}, Hour_Delta: {}'.format(dt1, t_delta))
        # assert(dt1 == dt2)
        t_constr = iris.Constraint(time=dt1)
        cubes_slice = cubes_out.extract(t_constr)
        p_cubes = iris.cube.CubeList()
        s_cubes = iris.cube.CubeList()
        if conf['unrotate_winds']:
            u = cubes_slice.extract('x_wind', strict=True)
            v = cubes_slice.extract('y_wind', strict=True)
            _u, _v = unrotate_uv(u, v)
            u.data = _u.data
            v.data = _v.data
        for cube_slice in cubes_slice:  # cubes_out:
            # cube_slice = cube.extract(t_constr)
            if cube_slice.attributes['l_name'] in PNAMES:
                p_cubes.append(cube_slice)
            if cube_slice.attributes['l_name'] in SNAMES:
                s_cubes.append(cube_slice)
        # print(p_cubes)
        # print()
        # print(s_cubes)
        # break
        for ds, fmask, master in zip((p_cubes, s_cubes),
                                     (pfile_mask, sfile_mask),
                                     ('x_wind', 'air_temperature')):
            thefile = fmask.format(dt=dt1)

            with nc.Dataset(thefile, mode='w') as ncds:
                ncds = cubelist_to_netcdf(ds, ncds, t_delta,
                                          master_cube=master,
                                          constants_file_name=cst_file)
                for _cube in ds:
                    cube_to_ncvar(_cube, ncds)
                # print(ncds.variables.keys())

            if output_mode != 'local':
                rsync_args = ['rsync', '-avqP', thefile, dest]
                cmd = ', '.join(rsync_args)
                ierr = sb.check_call(rsync_args)
                if ierr:
                    print('Command\n{}resulted in\n{}'.format(cmd, ierr))
                else:
                    print('Done')


if __name__ == '__main__':
    sys.exit(main())
